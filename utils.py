#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Emby API å’Œ RSSHub ç»Ÿä¸€å·¥å…·æ¨¡å—
æ•´åˆæ‰€æœ‰å¯¼å…¥å™¨ä¸­çš„APIè°ƒç”¨æ–¹æ³•
"""
import os
import urllib.parse
import requests
import feedparser
import base64
import logging
import time
from typing import List, Dict, Any, Optional, Tuple
from configparser import ConfigParser

class EmbyAPI:
    """Emby API ç»Ÿä¸€æ¥å£ç±»"""
    
    def __init__(self, emby_server: str, emby_api_key: str, emby_user_id: str = None):
        self.emby_server = emby_server.rstrip('/')
        self.emby_api_key = emby_api_key
        self.emby_user_id = emby_user_id
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/537.36"
        })
        
        # ç¼“å­˜æœºåˆ¶
        self._cache = {
            'movies': None,
            'series': None,
            'collections': None,
            'cache_time': None
        }
        self._cache_duration = 300  # ç¼“å­˜5åˆ†é’Ÿ
    
    def _is_cache_valid(self, cache_type: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if self._cache[cache_type] is None:
            return False
        if self._cache['cache_time'] is None:
            return False
        
        current_time = time.time()
        return (current_time - self._cache['cache_time']) < self._cache_duration
    
    def _get_cached_data(self, cache_type: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜æ•°æ®"""
        if self._is_cache_valid(cache_type):
            logging.info(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ•°æ®: {cache_type}")
            return self._cache[cache_type]
        return None
    
    def _set_cached_data(self, cache_type: str, data: Dict):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        self._cache[cache_type] = data
        self._cache['cache_time'] = time.time()
        logging.info(f"ğŸ’¾ ç¼“å­˜æ•°æ®: {cache_type}")
    
    def _make_request(self, method: str, url: str, **kwargs) -> Optional[requests.Response]:
        """ç»Ÿä¸€çš„è¯·æ±‚æ–¹æ³•ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
        max_retries = 3
        retry_delay = 2
        
        for attempt in range(max_retries):
            try:
                logging.info(f"ğŸ”„ å°è¯•ç¬¬ {attempt + 1} æ¬¡è¯·æ±‚: {method} {url}")
                response = self.session.request(method, url, timeout=30, **kwargs)
                logging.info(f"ğŸ“Š å“åº”çŠ¶æ€ç : {response.status_code}")
                
                # å¤„ç†æ•°æ®åº“å¼‚å¸¸
                if response.status_code == 500 and "SQLitePCL.pretty.SQLiteException" in response.text:
                    logging.warning(f"âš ï¸ Emby æ•°æ®åº“å¼‚å¸¸ï¼Œå°è¯•é‡è¯• ({attempt + 1}/{max_retries})")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
                        continue
                    else:
                        logging.error("âŒ Emby æ•°æ®åº“å¼‚å¸¸ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                        return None
                
                # 204è¡¨ç¤ºæˆåŠŸä½†æ— å†…å®¹è¿”å›ï¼Œè¿™ä¹Ÿæ˜¯æˆåŠŸçš„å“åº”
                if response.status_code in [200, 204]:
                    return response
                else:
                    logging.error(f"âŒ API è¯·æ±‚å¤±è´¥: {response.status_code}")
                    logging.error(f"ğŸ” é”™è¯¯å“åº”: {response.text[:500]}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
                        continue
                    else:
                        return None
                        
            except requests.exceptions.RequestException as e:
                logging.error(f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                else:
                    return None
        
        return None
    
    def check_server_status(self) -> bool:
        """æ£€æŸ¥EmbyæœåŠ¡å™¨çŠ¶æ€"""
        try:
            url = f"{self.emby_server}/emby/System/Info?api_key={self.emby_api_key}"
            response = self._make_request('GET', url)
            if response:
                logging.info("âœ… Emby æœåŠ¡å™¨çŠ¶æ€æ­£å¸¸")
                return True
            else:
                logging.error("âŒ Emby æœåŠ¡å™¨çŠ¶æ€å¼‚å¸¸")
                return False
        except Exception as e:
            logging.error(f"âŒ æ£€æŸ¥ Emby çŠ¶æ€å¤±è´¥: {str(e)}")
            return False
    
    def search_item_by_name(self, name: str, item_type: str = "Movie", year: str = None, 
                           ignore_played: bool = False) -> Optional[Dict]:
        """æ ¹æ®åç§°æœç´¢åª’ä½“é¡¹ç›®"""
        # æ„å»ºæœç´¢å‚æ•°
        emby_user_id = ""
        ignore_played_param = ""
        year_param = ""
        
        if item_type == "Series":
            include_item_types = "IncludeItemTypes=Series"
        else:
            include_item_types = "IncludeItemTypes=Movie"
        
        if ignore_played and self.emby_user_id:
            ignore_played_param = "&Filters=IsUnplayed"
            emby_user_id = f"Users/{self.emby_user_id}"
        
        if year:
            year_param = f"&Year={year}"
        
        # æ„å»ºURL
        search_term = urllib.parse.quote(name)
        url = f"{self.emby_server}/emby/{emby_user_id}/Items?api_key={self.emby_api_key}{ignore_played_param}&Recursive=true&{include_item_types}&SearchTerm={search_term}{year_param}"
        
        logging.info(f"ğŸ” æœç´¢é¡¹ç›®: {name} (ç±»å‹: {item_type}, å¹´ä»½: {year})")
        
        response = self._make_request('GET', url)
        if not response:
            return None
        
        try:
            data = response.json()
            total_count = data.get('TotalRecordCount', 0)
            logging.info(f"ğŸ“ˆ æ‰¾åˆ° {total_count} ä¸ªåŒ¹é…é¡¹ç›®")
            
            if total_count > 0:
                for item in data.get('Items', []):
                    if item['Name'] == name:
                        logging.info(f"âœ… æ‰¾åˆ°åŒ¹é…é¡¹ç›®: {item['Name']} (ID: {item.get('Id', 'N/A')})")
                        return item
                logging.warning(f"âš ï¸ æœªæ‰¾åˆ°å®Œå…¨åŒ¹é…çš„é¡¹ç›®: {name}")
                return None
            else:
                logging.info(f"â„¹ï¸ æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„é¡¹ç›®: {name}")
                return None
                
        except ValueError as e:
            logging.error(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return None
    
    def create_collection(self, collection_name: str, initial_item_id: str) -> Optional[str]:
        """åˆ›å»ºåˆé›†"""
        encoded_name = urllib.parse.quote(collection_name, safe='')
        url = f"{self.emby_server}/emby/Collections?IsLocked=false&Name={encoded_name}&Ids={initial_item_id}&api_key={self.emby_api_key}"
        headers = {"accept": "application/json"}
        
        logging.info(f"ğŸ”¨ åˆ›å»ºåˆé›†: {collection_name}")
        
        response = self._make_request('POST', url, headers=headers)
        if not response:
            return None
        
        try:
            collection_id = response.json().get('Id')
            if collection_id:
                logging.info(f"âœ… æˆåŠŸåˆ›å»ºåˆé›†: {collection_id}")
                return collection_id
            else:
                logging.error("âŒ åˆ›å»ºåˆé›†å¤±è´¥: æœªè¿”å›ID")
                return None
        except ValueError as e:
            logging.error(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return None
    
    def add_item_to_collection(self, item_id: str, collection_id: str) -> bool:
        """æ·»åŠ é¡¹ç›®åˆ°åˆé›†"""
        url = f"{self.emby_server}/emby/Collections/{collection_id}/Items?Ids={item_id}&api_key={self.emby_api_key}"
        headers = {"accept": "application/json"}
        
        logging.info(f"â• æ·»åŠ é¡¹ç›®åˆ°åˆé›†: item_id={item_id}, collection_id={collection_id}")
        
        response = self._make_request('POST', url, headers=headers)
        if response:
            if response.status_code == 204:
                logging.info(f"âœ… æˆåŠŸæ·»åŠ é¡¹ç›®åˆ°åˆé›† (çŠ¶æ€ç : 204 - æ— å†…å®¹)")
            else:
                logging.info(f"âœ… æˆåŠŸæ·»åŠ é¡¹ç›®åˆ°åˆé›† (çŠ¶æ€ç : {response.status_code})")
            return True
        else:
            logging.error(f"âŒ æ·»åŠ é¡¹ç›®åˆ°åˆé›†å¤±è´¥")
            return False
    
    def check_collection_exists(self, collection_name: str) -> Optional[Dict]:
        """æ£€æŸ¥åˆé›†æ˜¯å¦å­˜åœ¨"""
        # å…ˆå°è¯•ä»ç¼“å­˜è·å–
        cached_collections = self._get_cached_data('collections')
        if cached_collections:
            for collection in cached_collections:
                if collection.get('Name') == collection_name:
                    return collection
        
        # ä»æœåŠ¡å™¨è·å–
        encoded_name = urllib.parse.quote(collection_name, safe='')
        url = f"{self.emby_server}/Items?IncludeItemTypes=BoxSet&Recursive=true&SearchTerm={encoded_name}&api_key={self.emby_api_key}"
        
        logging.info(f"ğŸ” æ£€æŸ¥åˆé›†æ˜¯å¦å­˜åœ¨: {collection_name}")
        
        response = self._make_request('GET', url)
        if not response:
            return None
        
        try:
            data = response.json()
            for item in data.get('Items', []):
                if item.get('Name') == collection_name:
                    logging.info(f"âœ… æ‰¾åˆ°åˆé›†: {collection_name} (ID: {item.get('Id')})")
                    return item
            
            logging.info(f"â„¹ï¸ åˆé›†ä¸å­˜åœ¨: {collection_name}")
            return None
            
        except ValueError as e:
            logging.error(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return None
    
    def get_collection_items(self, collection_id: str) -> List[str]:
        """è·å–åˆé›†ä¸­çš„æ‰€æœ‰é¡¹ç›®åç§°"""
        url = f"{self.emby_server}/emby/Items?api_key={self.emby_api_key}&ParentId={collection_id}"
        
        logging.info(f"ğŸ“‹ è·å–åˆé›†é¡¹ç›®: collection_id={collection_id}")
        
        response = self._make_request('GET', url)
        if not response:
            return []
        
        try:
            data = response.json()
            items = [item.get('Name', '') for item in data.get('Items', [])]
            logging.info(f"ğŸ“ˆ åˆé›†åŒ…å« {len(items)} ä¸ªé¡¹ç›®")
            return items
        except ValueError as e:
            logging.error(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return []
    
    def clear_collection(self, collection_id: str) -> bool:
        """æ¸…ç©ºåˆé›†"""
        url = f"{self.emby_server}/emby/Collections/{collection_id}/Items/Delete"
        params = {"api_key": self.emby_api_key}
        
        logging.info(f"ğŸ—‘ï¸ æ¸…ç©ºåˆé›†: collection_id={collection_id}")
        
        response = self._make_request('POST', url, params=params)
        if response:
            if response.status_code == 204:
                logging.info(f"âœ… æˆåŠŸæ¸…ç©ºåˆé›† (çŠ¶æ€ç : 204 - æ— å†…å®¹)")
            else:
                logging.info(f"âœ… æˆåŠŸæ¸…ç©ºåˆé›† (çŠ¶æ€ç : {response.status_code})")
            return True
        else:
            logging.error(f"âŒ æ¸…ç©ºåˆé›†å¤±è´¥")
            return False
    
    def replace_collection_cover(self, collection_id: str, image_url: str) -> bool:
        """æ›¿æ¢åˆé›†å°é¢"""
        try:
            # ä¸‹è½½å›¾ç‰‡
            image_response = requests.get(image_url, timeout=30)
            if image_response.status_code != 200:
                logging.error(f"âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥: {image_response.status_code}")
                return False
            
            # è½¬æ¢ä¸ºbase64
            base64_image = base64.b64encode(image_response.content)
            
            # ä¸Šä¼ åˆ°Emby
            url = f'{self.emby_server}/emby/Items/{collection_id}/Images/Primary?api_key={self.emby_api_key}'
            headers = {
                'Content-Type': 'image/jpeg',
                'X-Emby-Token': self.emby_api_key
            }
            
            logging.info(f"ğŸ–¼ï¸ æ›¿æ¢åˆé›†å°é¢: collection_id={collection_id}")
            
            response = self._make_request('POST', url, headers=headers, data=base64_image)
            if response:
                if response.status_code == 204:
                    logging.info(f"âœ… æˆåŠŸæ›¿æ¢åˆé›†å°é¢ (çŠ¶æ€ç : 204 - æ— å†…å®¹)")
                else:
                    logging.info(f"âœ… æˆåŠŸæ›¿æ¢åˆé›†å°é¢ (çŠ¶æ€ç : {response.status_code})")
                return True
            else:
                logging.error(f"âŒ æ›¿æ¢åˆé›†å°é¢å¤±è´¥")
                return False
                
        except Exception as e:
            logging.error(f"âŒ æ›¿æ¢å°é¢å¼‚å¸¸: {str(e)}")
            return False
    
    def get_all_collections(self) -> List[Dict]:
        """è·å–æ‰€æœ‰åˆé›†"""
        cached_collections = self._get_cached_data('collections')
        if cached_collections:
            return cached_collections
        
        url = f"{self.emby_server}/Items?IncludeItemTypes=BoxSet&Recursive=true&api_key={self.emby_api_key}"
        
        logging.info("ğŸ“‹ è·å–æ‰€æœ‰åˆé›†")
        
        response = self._make_request('GET', url)
        if not response:
            return []
        
        try:
            data = response.json()
            collections = data.get('Items', [])
            self._set_cached_data('collections', collections)
            logging.info(f"ğŸ“ˆ æ‰¾åˆ° {len(collections)} ä¸ªåˆé›†")
            return collections
        except ValueError as e:
            logging.error(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
            return []


class RSSHubAPI:
    """RSSHub API ç»Ÿä¸€æ¥å£ç±»"""
    
    def __init__(self, rsshub_server: str, name_mapping: dict = None):
        self.rsshub_server = rsshub_server.rstrip('/')
        self.name_mapping = name_mapping or {}
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/537.36"
        })
    
    def get_douban_movie_rss(self, rss_id: str) -> Optional[Dict]:
        """è·å–è±†ç“£ç”µå½±RSSæ•°æ®"""
        rss_url = f"{self.rsshub_server}/douban/movie/weekly/{rss_id}"
        
        logging.info(f"ğŸ“¡ è·å–è±†ç“£ç”µå½±RSS: {rss_id}")
        
        try:
            response = self.session.get(rss_url, timeout=30)
            if response.status_code != 200:
                logging.error(f"âŒ RSSè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
            
            feed = feedparser.parse(rss_url)
            if not feed.entries:
                logging.error(f"âŒ RSSæ•°æ®ä¸ºç©º: {rss_url}")
                return None
            
            movies = []
            for item in feed.entries:
                name = item.title.strip() if item.title else ""
                if not name:
                    continue
                
                # æå–å¹´ä»½
                year = None
                if hasattr(item, 'year') and item.year:
                    year = item.year
                
                # ç¡®å®šç±»å‹
                media_type = getattr(item, 'type', 'movie')
                if media_type == 'book':
                    continue
                if media_type == 'tv':
                    name = re.sub(r" ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+å­£", "", name)
                
                movies.append({
                    'name': name,
                    'year': year,
                    'type': media_type
                })
            
            result = {
                'title': feed.feed.title if hasattr(feed.feed, 'title') else f'è±†ç“£{rss_id}',
                'movies': movies
            }
            
            logging.info(f"âœ… æˆåŠŸè·å–RSSæ•°æ®: {len(movies)} éƒ¨ç”µå½±")
            return result
            
        except Exception as e:
            logging.error(f"âŒ è·å–RSSæ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def get_douban_doulist_rss(self, doulist_id: str) -> Optional[Dict]:
        """è·å–è±†ç“£è±†åˆ—RSSæ•°æ®"""
        rss_url = f"{self.rsshub_server}/douban/doulist/{doulist_id}"
        
        logging.info(f"ğŸ“¡ è·å–è±†ç“£è±†åˆ—RSS: {doulist_id}")
        
        try:
            response = self.session.get(rss_url, timeout=30)
            if response.status_code != 200:
                logging.error(f"âŒ RSSè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
            
            feed = feedparser.parse(rss_url)
            if not feed.entries:
                logging.error(f"âŒ RSSæ•°æ®ä¸ºç©º: {rss_url}")
                return None
            
            movies = []
            for item in feed.entries:
                raw_title = item.title.strip() if item.title else ""
                if not raw_title or re.match(r'^[\s\-â€”â€“]*$', raw_title):
                    continue
                
                # æå–ç®€ä½“åç§°
                name = raw_title
                simplified_name_match = re.match(r'([^\s]+)', name)
                if simplified_name_match:
                    name = simplified_name_match.group(1)
                
                # åº”ç”¨åç§°æ˜ å°„
                name = self.name_mapping.get(name, name)
                
                # ä»æè¿°ä¸­æå–å¹´ä»½å’Œç±»å‹
                description = item.description
                year = None
                media_type = "movie"
                
                year_match = re.search(r'å¹´ä»½:\s*(\d{4})', description)
                if year_match:
                    year = year_match.group(1)
                
                type_match = re.search(r'ç±»å‹:\s*([^<]+)', description)
                if type_match:
                    types = type_match.group(1).strip()
                    if "å‰§æƒ…" in types or "ç”µå½±" in types or "çˆ±æƒ…" in types or "åŒæ€§" in types:
                        media_type = "movie"
                    elif "ç”µè§†å‰§" in types or "å‰§é›†" in types:
                        media_type = "tv"
                
                if media_type == 'book':
                    continue
                if media_type == "tv":
                    name = re.sub(r" ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+å­£", "", name)
                
                movies.append({
                    'name': name,
                    'year': year,
                    'type': media_type
                })
            
            result = {
                'title': feed.feed.title if hasattr(feed.feed, 'title') else f'è±†åˆ—{doulist_id}',
                'movies': movies
            }
            
            logging.info(f"âœ… æˆåŠŸè·å–è±†åˆ—RSSæ•°æ®: {len(movies)} éƒ¨ç”µå½±")
            return result
            
        except Exception as e:
            logging.error(f"âŒ è·å–è±†åˆ—RSSæ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def get_bangumi_calendar(self) -> Optional[Dict]:
        """è·å–Bangumiæ—¥å†æ•°æ®"""
        rss_url = "https://api.bgm.tv/calendar"
        
        logging.info("ğŸ“¡ è·å–Bangumiæ—¥å†æ•°æ®")
        
        try:
            response = self.session.get(rss_url, timeout=30)
            if response.status_code != 200:
                logging.error(f"âŒ Bangumi APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return None
            
            data = response.json()
            movies = []
            
            for entry in data:
                title = entry.get('weekday', {}).get('cn', 'æœªçŸ¥åˆ†ç±»')
                for item in entry.get('items', []):
                    name = item.get('name_cn') or item.get('name')
                    year = None
                    
                    air_date = item.get('air_date')
                    if air_date:
                        year_match = re.search(r'(\d{4})', air_date)
                        if year_match:
                            year = year_match.group(1)
                    
                    media_type = 'tv' if item.get('type') == 2 else 'movie'
                    
                    if media_type == 'book':
                        continue
                    if media_type == 'tv':
                        name = re.sub(r" ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+å­£", "", name)
                    
                    movies.append({
                        'name': name,
                        'year': year,
                        'type': media_type
                    })
            
            result = {
                'title': 'Bangumiæ—¥å†',
                'movies': movies
            }
            
            logging.info(f"âœ… æˆåŠŸè·å–Bangumiæ•°æ®: {len(movies)} éƒ¨ä½œå“")
            return result
            
        except Exception as e:
            logging.error(f"âŒ è·å–Bangumiæ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def test_connection(self, rss_type: str, rss_id: str) -> bool:
        """æµ‹è¯•RSSè¿æ¥"""
        if rss_type == 'douban_movie':
            rss_url = f"{self.rsshub_server}/douban/movie/weekly/{rss_id}"
        elif rss_type == 'douban_doulist':
            rss_url = f"{self.rsshub_server}/douban/doulist/{rss_id}"
        else:
            logging.error(f"âŒ ä¸æ”¯æŒçš„RSSç±»å‹: {rss_type}")
            return False
        
        logging.info(f"ğŸ§ª æµ‹è¯•RSSè¿æ¥: {rss_url}")
        
        try:
            response = self.session.get(rss_url, timeout=30)
            logging.info(f"ğŸ“Š RSSå“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                feed = feedparser.parse(rss_url)
                if feed.entries:
                    logging.info(f"âœ… RSSè¿æ¥æ­£å¸¸ï¼Œæ‰¾åˆ°{len(feed.entries)}ä¸ªæ¡ç›®")
                    return True
                else:
                    logging.error("âŒ RSSè§£ææˆåŠŸä½†æ— æ¡ç›®")
                    return False
            else:
                logging.error(f"âŒ RSSè¯·æ±‚å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            logging.error(f"âŒ RSSè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            return False


# å¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—
import re 