#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSVæ–‡ä»¶ç®¡ç†å·¥å…·
ç”¨äºæŸ¥çœ‹å’Œç®¡ç†missing_movies.csvæ–‡ä»¶
"""
import os
import csv
import pandas as pd
from datetime import datetime
from configparser import ConfigParser
import argparse

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config = ConfigParser()
    config.read('config.conf')
    return config

def view_csv():
    """æŸ¥çœ‹CSVæ–‡ä»¶å†…å®¹"""
    config = load_config()
    csv_file_path = config.get('Output', 'csv_file_path')
    
    if not os.path.exists(csv_file_path):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return
    
    try:
        # ä½¿ç”¨pandasè¯»å–CSVæ–‡ä»¶
        df = pd.read_csv(csv_file_path)
        
        print(f"ğŸ“Š CSVæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯:")
        print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {csv_file_path}")
        print(f"ğŸ“ˆ æ€»è®°å½•æ•°: {len(df)}")
        print(f"ğŸ“… æœ€åä¿®æ”¹: {datetime.fromtimestamp(os.path.getmtime(csv_file_path))}")
        
        if len(df) > 0:
            print(f"\nğŸ“‹ æŒ‰å¯¼å…¥å™¨ç»Ÿè®¡:")
            importer_stats = df['å¯¼å…¥å™¨'].value_counts()
            for importer, count in importer_stats.items():
                print(f"  {importer}: {count} æ¡è®°å½•")
            
            print(f"\nğŸ“‹ æŒ‰åˆé›†ç»Ÿè®¡ (å‰10ä¸ª):")
            collection_stats = df['åˆé›†åç§°'].value_counts().head(10)
            for collection, count in collection_stats.items():
                print(f"  {collection}: {count} æ¡è®°å½•")
            
            print(f"\nğŸ“‹ æœ€æ–°è®°å½• (å‰10æ¡):")
            print(df.tail(10).to_string(index=False))
        else:
            print("ğŸ“­ CSVæ–‡ä»¶ä¸ºç©º")
            
    except Exception as e:
        print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")

def export_by_importer(importer_name):
    """æŒ‰å¯¼å…¥å™¨å¯¼å‡ºCSV"""
    config = load_config()
    csv_file_path = config.get('Output', 'csv_file_path')
    
    if not os.path.exists(csv_file_path):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return
    
    try:
        df = pd.read_csv(csv_file_path)
        
        # è¿‡æ»¤æŒ‡å®šå¯¼å…¥å™¨çš„è®°å½•
        filtered_df = df[df['å¯¼å…¥å™¨'] == importer_name]
        
        if len(filtered_df) == 0:
            print(f"âŒ æœªæ‰¾åˆ°å¯¼å…¥å™¨ '{importer_name}' çš„è®°å½•")
            return
        
        # å¯¼å‡ºåˆ°æ–°æ–‡ä»¶
        output_file = f"missing_movies_{importer_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        filtered_df.to_csv(output_file, index=False, encoding='utf-8')
        
        print(f"âœ… æˆåŠŸå¯¼å‡º {len(filtered_df)} æ¡è®°å½•åˆ°: {output_file}")
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")

def export_by_collection(collection_name):
    """æŒ‰åˆé›†å¯¼å‡ºCSV"""
    config = load_config()
    csv_file_path = config.get('Output', 'csv_file_path')
    
    if not os.path.exists(csv_file_path):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return
    
    try:
        df = pd.read_csv(csv_file_path)
        
        # è¿‡æ»¤æŒ‡å®šåˆé›†çš„è®°å½•
        filtered_df = df[df['åˆé›†åç§°'] == collection_name]
        
        if len(filtered_df) == 0:
            print(f"âŒ æœªæ‰¾åˆ°åˆé›† '{collection_name}' çš„è®°å½•")
            return
        
        # å¯¼å‡ºåˆ°æ–°æ–‡ä»¶
        output_file = f"missing_movies_{collection_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        filtered_df.to_csv(output_file, index=False, encoding='utf-8')
        
        print(f"âœ… æˆåŠŸå¯¼å‡º {len(filtered_df)} æ¡è®°å½•åˆ°: {output_file}")
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")

def clear_csv():
    """æ¸…ç©ºCSVæ–‡ä»¶"""
    config = load_config()
    csv_file_path = config.get('Output', 'csv_file_path')
    
    if not os.path.exists(csv_file_path):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return
    
    try:
        # å¤‡ä»½åŸæ–‡ä»¶
        backup_file = f"{csv_file_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.rename(csv_file_path, backup_file)
        
        # åˆ›å»ºæ–°çš„ç©ºæ–‡ä»¶
        with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(['ç”µå½±åç§°', 'å¹´ä»½', 'åˆé›†åç§°', 'å¯¼å…¥å™¨', 'è®°å½•æ—¶é—´'])
        
        print(f"âœ… æˆåŠŸæ¸…ç©ºCSVæ–‡ä»¶")
        print(f"ğŸ“ åŸæ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_file}")
        
    except Exception as e:
        print(f"âŒ æ¸…ç©ºå¤±è´¥: {str(e)}")

def backup_csv():
    """å¤‡ä»½CSVæ–‡ä»¶"""
    config = load_config()
    csv_file_path = config.get('Output', 'csv_file_path')
    
    if not os.path.exists(csv_file_path):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return
    
    try:
        # åˆ›å»ºå¤‡ä»½æ–‡ä»¶
        backup_file = f"{csv_file_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        import shutil
        shutil.copy2(csv_file_path, backup_file)
        
        print(f"âœ… æˆåŠŸå¤‡ä»½CSVæ–‡ä»¶")
        print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶: {backup_file}")
        
    except Exception as e:
        print(f"âŒ å¤‡ä»½å¤±è´¥: {str(e)}")

def reset_csv():
    """é‡ç½®CSVæ–‡ä»¶ï¼ˆæ¸…ç©ºä½†ä¸å¤‡ä»½ï¼‰"""
    config = load_config()
    csv_file_path = config.get('Output', 'csv_file_path')
    
    try:
        # ç›´æ¥åˆ›å»ºæ–°çš„ç©ºæ–‡ä»¶
        with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(['ç”µå½±åç§°', 'å¹´ä»½', 'åˆé›†åç§°', 'å¯¼å…¥å™¨', 'è®°å½•æ—¶é—´'])
        
        print(f"âœ… æˆåŠŸé‡ç½®CSVæ–‡ä»¶")
        print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {csv_file_path}")
        
    except Exception as e:
        print(f"âŒ é‡ç½®å¤±è´¥: {str(e)}")

def search_csv(keyword):
    """æœç´¢CSVæ–‡ä»¶"""
    config = load_config()
    csv_file_path = config.get('Output', 'csv_file_path')
    
    if not os.path.exists(csv_file_path):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return
    
    try:
        df = pd.read_csv(csv_file_path)
        
        # åœ¨æ‰€æœ‰æ–‡æœ¬åˆ—ä¸­æœç´¢å…³é”®è¯
        mask = df.apply(lambda x: x.astype(str).str.contains(keyword, case=False, na=False)).any(axis=1)
        filtered_df = df[mask]
        
        if len(filtered_df) == 0:
            print(f"âŒ æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ '{keyword}' çš„è®°å½•")
            return
        
        print(f"ğŸ” æ‰¾åˆ° {len(filtered_df)} æ¡åŒ…å«å…³é”®è¯ '{keyword}' çš„è®°å½•:")
        print(filtered_df.to_string(index=False))
        
    except Exception as e:
        print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")

def main():
    parser = argparse.ArgumentParser(description='CSVæ–‡ä»¶ç®¡ç†å·¥å…·')
    parser.add_argument('action', choices=['view', 'export-importer', 'export-collection', 'clear', 'backup', 'reset', 'search'], 
                       help='æ“ä½œç±»å‹')
    parser.add_argument('--name', help='å¯¼å…¥å™¨åç§°æˆ–åˆé›†åç§°')
    parser.add_argument('--keyword', help='æœç´¢å…³é”®è¯')
    
    args = parser.parse_args()
    
    if args.action == 'view':
        view_csv()
    elif args.action == 'export-importer':
        if not args.name:
            print("âŒ è¯·æŒ‡å®šå¯¼å…¥å™¨åç§°: --name <å¯¼å…¥å™¨åç§°>")
            return
        export_by_importer(args.name)
    elif args.action == 'export-collection':
        if not args.name:
            print("âŒ è¯·æŒ‡å®šåˆé›†åç§°: --name <åˆé›†åç§°>")
            return
        export_by_collection(args.name)
    elif args.action == 'clear':
        clear_csv()
    elif args.action == 'backup':
        backup_csv()
    elif args.action == 'reset':
        reset_csv()
    elif args.action == 'search':
        if not args.keyword:
            print("âŒ è¯·æŒ‡å®šæœç´¢å…³é”®è¯: --keyword <å…³é”®è¯>")
            return
        search_csv(args.keyword)

if __name__ == "__main__":
    main() 